[["bayesian.html", "Chapter7 Bayesian analysis 7.1 Generating the data 7.2 Comparing the actual and estimated values from ML and Bayesian 7.3 Bayesian estimates easily", " Chapter7 Bayesian analysis In this part we are going to estimate the same parameters of a model equal to the best model which was selected in the unmarked model selection procedure in the previous chapter. Recall that this model has beta1 and alpha1, alpha2, alpha3. The parameters that we will estimate with the Bayesian method are going to be compared with the parameters that we already estimated with ML in unmarked and we will also compare them with the real parameters that we defined when establishing the data (data2) with the function data.fn, to see which of the two estimation methods (ML or Bayesian) are closer to the real parameters. 7.1 Generating the data Again we will use a TEAM-type design (https://www.wildlifeinsights.org/team-network) with 60 sampling sites and 30 repeated visits, which is equivalent to the 30 days that the cameras remain active in the field. Our species remains the same, the white-tailed deer. For this example we will assume that detection is 0.6, occupancy is 0.8, and the interactions are simple with altitude as the only covariate explaining occupancy. But for detection there is a more complex relationship, assuming there is a slight interaction between the observation covariates. For observation, altitude and temperature interact with each other. Also note how altitude influences in opposite directions with a positive altitude sign for detection and a negative sign for occupancy. # ### Generate a new data set or use the same # # **************************************** # set.seed(148) # data &lt;- data.fn(show.plot = T) # Default arguments # str(data) # Look at the object # we are oing to use the data from datos2 object ### Fit same model with JAGS, using library jagsUI # ************************************************ # Bundle data win.data &lt;- list(y = datos2$y, M = nrow(datos2$y), J = ncol(datos2$y), elev = datos2$elev, forest = datos2$forest, temp = datos2$temp) # str(win.data) # # Specify model in BUGS language # sink(&quot;model22.txt&quot;) # cat(&quot; # model { # # # Priors # mean.p ~ dunif(0, 1) # Detection intercept on prob. scale # alpha0 &lt;- logit(mean.p) # same on logit scale # mean.psi ~ dunif(0, 1) # Occupancy intercept on prob. scale # beta0 &lt;- logit(mean.psi) # same on logit scale # for(k in 1:3){ # 2 detection covariates + 1 interact # alpha[k] ~ dnorm(0, 0.01) # Covariates on logit(detection) # # alpha[k] ~ dnorm(0, 0.05) # Covariates on logit(detection) # # alpha[k] ~ dunif(-10, 10) # Covariates on logit(detection) # } # # for(k in 1:1){ # 2 occupancy covariates + 1 interact # beta[k] ~ dnorm(0, 0.01) # Covariates on logit(occupancy) # # beta[k] ~ dnorm(0, 0.05) # Covariates on logit(occupancy) # # beta[k] ~ dunif(-10, 10) # Covariates on logit(occupancy) # } # # # Translation of the occupancy parameters in unmarked into those for BUGS: # # (Intercept) (beta0 in BUGS) # # elev (beta[1]) # # forest (beta[2]) # # temp (beta[3]) # # elev:forest (beta[4]) # # elev:temp (beta[5]) # # forest:temp (beta[6]) # # elev:forest:temp (beta[7]) # # # # Likelihood # for (i in 1:M) { # # True state model for the partially observed true state # z[i] ~ dbern(psi[i]) # True occupancy z at site i # logit(psi[i]) &lt;- beta0 + # occupancy (psi) intercept # beta[1] * elev[i] #+ # elev # #beta[2] * forest[i] #+ # forest # #beta[3] * elev[i] * forest[i] # elev:forest # #beta[4] * elev[i] * temp[i] + # elev:temp # #beta[5] * temp[i] + # temp # #beta[6] * forest[i] * temp[i] + # forest:temp # #beta[7] * elev[i] * forest[i] * temp[i] # elev:forest:temp # # for (j in 1:J) { # # Observation model for the actual observations # y[i,j] ~ dbern(p.eff[i,j]) # Detection-nondetection at i and j # p.eff[i,j] &lt;- z[i] * p[i,j] # logit(p[i,j]) &lt;- alpha0 + # detection (p) intercept # alpha[1] * elev[i] + # effect of elevation on p # alpha[2] * temp[i,j] + # effect of temp on p # alpha[3] * elev[i] * temp[i,j] # effect of elev:temp on p # } # } # # # Derived quantities # sumZ &lt;- sum(z[]) # Number of occupied sites among those studied # occ.fs &lt;- sum(z[])/M # proportion of occupied sites among those studied # logit.psi &lt;- beta0 # For comparison with unmarked # logit.p &lt;- alpha0 # For comparison with unmarked # } # &quot;,fill = TRUE) # sink() library(jagsUI) # library(R2jags) # Initial values zst &lt;- apply(datos2$y, 1, max) inits &lt;- function(){list(z = zst, mean.psi = runif(1), mean.p = runif(1), alpha = rnorm(3), # adjust here beta = rnorm(1))} # adjust here # Parameters monitored params &lt;- c(&quot;sumZ&quot;, &quot;occ.fs&quot;, &quot;logit.psi&quot;, &quot;logit.p&quot;, &quot;alpha&quot;, &quot;beta&quot;) # MCMC settings # ni &lt;- 100000 ; nt &lt;- 10 ; nb &lt;- 1000 ; nc &lt;- 3 ni &lt;- 10000 ; nt &lt;- 10 ; nb &lt;- 500 ; nc &lt;- 3 # Call JAGS from R (ART 260 sec with norm(), 480 with unif(-10,10)) # and summarize posteriors system.time(out22 &lt;- jags(win.data, inits, parameters.to.save = params, model.file = &quot;D:/BoxFiles/Box Sync/CodigoR/Toshiba/IntroOccuBook/bookdown-demo-master/model22.txt&quot;, n.chains = nc, n.thin = nt, n.iter = ni, n.burnin = nb, parallel = T)) ## ## Processing function input....... ## ## Done. ## ## Beginning parallel processing using 3 cores. Console output will be suppressed. ## ## Parallel processing completed. ## ## Calculating statistics....... ## ## Done. ## user system elapsed ## 0.04 0.02 233.16 # See model diagnistics and convergence library(mcmcplots) library(ggmcmc) fit22.mcmc &lt;- as.mcmc.list(out22$samples) bayes.mod.fit.gg &lt;- ggs(fit22.mcmc) #convert to ggmcmc ggs_running(bayes.mod.fit.gg)# check if chains approach target distrib. # denplot(fit22.mcmc, parms = c(&quot;beta&quot;, # &quot;alpha[1]&quot;, &quot;alpha[2]&quot;, &quot;alpha[3]&quot;, # &quot;logit.psi&quot;, &quot;logit.p&quot; )) # traplot(fit22.mcmc) # ggs_density(bayes.mod.fit.gg) # xyplot(out22) # assess within-chain convergence densityplot(out22) # shape of the posterior distribution # see model result and estimates print(out22, 3) ## JAGS output for model &#39;D:/BoxFiles/Box Sync/CodigoR/Toshiba/IntroOccuBook/bookdown-demo-master/model22.txt&#39;, generated by jagsUI. ## Estimates based on 3 chains of 10000 iterations, ## adaptation = 100 iterations (sufficient), ## burn-in = 500 iterations and thin rate = 10, ## yielding 2850 total samples from the joint posterior. ## MCMC ran in parallel for 3.884 minutes at time 2022-06-25 22:47:58. ## ## mean sd 2.5% 50% 97.5% overlap0 f Rhat n.eff ## sumZ 46.029 0.168 46.000 46.000 47.000 FALSE 1.000 1.000 2850 ## occ.fs 0.767 0.003 0.767 0.767 0.783 FALSE 1.000 1.000 2850 ## logit.psi 1.173 0.324 0.562 1.163 1.825 FALSE 1.000 1.000 2850 ## logit.p 0.408 0.074 0.263 0.407 0.560 FALSE 1.000 1.001 2372 ## alpha[1] 2.147 0.152 1.853 2.143 2.445 FALSE 1.000 1.000 2850 ## alpha[2] 0.902 0.126 0.657 0.903 1.155 FALSE 1.000 1.000 2850 ## alpha[3] 1.686 0.247 1.208 1.682 2.180 FALSE 1.000 1.000 2850 ## beta -1.475 0.632 -2.769 -1.458 -0.329 FALSE 0.995 1.000 2850 ## deviance 1589.362 3.508 1585.504 1588.480 1599.696 FALSE 1.000 1.000 2850 ## ## Successful convergence based on Rhat values (all &lt; 1.1). ## Rhat is the potential scale reduction factor (at convergence, Rhat=1). ## For each parameter, n.eff is a crude measure of effective sample size. ## ## overlap0 checks if 0 falls in the parameter&#39;s 95% credible interval. ## f is the proportion of the posterior with the same sign as the mean; ## i.e., our confidence that the parameter is positive or negative. ## ## DIC info: (pD = var(deviance)/2) ## pD = 6.2 and DIC = 1595.517 ## DIC is an estimate of expected predictive error (lower is better). # store in tmp coefficients from best ML model tmp &lt;- summary(fm7) ## ## Call: ## occu(formula = ~elev + temp + elev:temp ~ elev, data = umf) ## ## Occupancy (logit-scale): ## Estimate SE z P(&gt;|z|) ## (Intercept) 1.18 0.326 3.62 0.000291 ## elev -1.41 0.624 -2.26 0.023548 ## ## Detection (logit-scale): ## Estimate SE z P(&gt;|z|) ## (Intercept) 0.407 0.0735 5.54 3.03e-08 ## elev 2.140 0.1494 14.32 1.66e-46 ## temp 0.900 0.1262 7.14 9.68e-13 ## elev:temp 1.680 0.2514 6.68 2.34e-11 ## ## AIC: 1656.533 ## Number of sites: 60 ## optim convergence code: 0 ## optim iterations: 38 ## Bootstrap iterations: 0 modestimates &lt;- cbind(rbind(tmp$state[1:2], tmp$det[1:2]), Post.mean = out22$summary[c(3, 8, 4:7), 1], Post.sd = out22$summary[c(3, 8, 4:7), 2] ) # fix the(logit-scale) in unmarked modestimates[1,1]&lt;- plogis(modestimates[1,1]) modestimates[3,1]&lt;- plogis(modestimates[3,1]) # fix the(logit-scale) in Bayes in logit.psi logit.p modestimates[1,3]&lt;- plogis(modestimates[1,3]) modestimates[3,3]&lt;- plogis(modestimates[3,3]) # get real values from datos2 object real&lt;- rbind(datos2$mean.occupancy, datos2$beta1, datos2$mean.detection, datos2$alpha1, datos2$alpha2, datos2$alpha3) 7.2 Comparing the actual and estimated values from ML and Bayesian Lets see how close the estimates are to the actual values, by comparing the actual value with the Maximum Likelihood estimate (columns 2 and 3) and the Bayesian estimate (columns 4 and 5). ### see if the values are close to real values compare &lt;- cbind(real, modestimates) # put both in same table # put names to rows rownames(compare) &lt;- c(&quot;psi&quot;,&quot;beta&quot;,&quot;p&quot;,&quot;alpha1&quot;,&quot;alpha2&quot;, &quot;alpha3&quot;) # print comparing table library(knitr) kable(compare) real Estimate SE Post.mean Post.sd psi 0.8 0.7653197 0.3262574 0.7637476 0.3244823 beta -1.5 -1.4129006 0.6239572 -1.4747848 0.6319201 p 0.6 0.6004304 0.0735178 0.6005410 0.0744655 alpha1 2.0 2.1395071 0.1494144 2.1470247 0.1515634 alpha2 1.0 0.9003900 0.1261927 0.9021164 0.1257829 alpha3 1.5 1.6801587 0.2513946 1.6858529 0.2468270 7.3 Bayesian estimates easily The JAGS code adds another layer of complexity to the analysis. Fortunately, since the year 2022, there is a new package in the neighborhood. The ubms package allows Bayesian estimates using the same easy and simple unmarked structure. The package has a formula-based interface compatible with unmarked, but the model is fit using MCMC with Stan instead of using maximum likelihood. ## ## Call: ## stan_occu(formula = ~elev + temp + elev:temp ~ elev, data = umf, ## chains = 3, cores = 3) ## ## Occupancy (logit-scale): ## Estimate SD 2.5% 97.5% n_eff Rhat ## (Intercept) 1.16 0.325 0.567 1.812 3548 1.000 ## elev -1.27 0.568 -2.447 -0.223 2970 0.999 ## ## Detection (logit-scale): ## Estimate SD 2.5% 97.5% n_eff Rhat ## (Intercept) 0.398 0.0742 0.257 0.555 3054 1 ## elev 2.117 0.1481 1.825 2.419 2670 1 ## temp 0.882 0.1272 0.633 1.134 2931 1 ## elev:temp 1.627 0.2514 1.129 2.147 3109 1 ## ## LOOIC: 1657.562 ## Runtime: 6.215 sec Advantages of ubms compared to unmarked: Obtain posterior distributions of parameters and derived parameters. Include random effects in parameter formulas (same syntax as lme4). Assess model fit using WAIC and LOO via the loo package. Disadvantages compared to unmarked: MCMC is slower than maximum likelihood. Not all model types are supported. Potential for convergence issues "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
